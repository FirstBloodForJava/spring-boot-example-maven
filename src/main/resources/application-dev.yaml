name: spring-kafka
server:
#  address: 127.0.0.1
  port: 8080

logging:
  config: classpath:logback-async.xml
spring:
  datasource:
    url: jdbc:h2:./tomcat/dateSourceTmp/gatewayDataSource
    driverClassName: org.h2.Driver
    username: user
    password: password
  jpa:
    database-platform: org.hibernate.dialect.H2Dialect
  kafka:
    bootstrapServers: 47.101.155.205:9092
    consumer:
      auto-commit-interval: 10S # 自动提交时间间隔 auto.commit.interval.ms
      auto-offset-reset: earliest # kafka server没有偏移量存在的策略 auto.offset.reset
      bootstrap-servers: 47.101.155.205:9092 # 指定 kafka 消费者kafka集群 bootstrap.servers
      client-id: local # 指定消费者 client.id配置 消费者日志上下文会打印，用于日志跟踪
      enable-auto-commit: true # 是否后台自动提交偏移量
      fetch-max-wait: 500 # fetch.max.wait.ms 消费一次 fetch.min.bytes 没达到这个标准的阻塞时间
      fetch-min-size: 1 # # 消费者请求一次最小的响应数据单位字节,如果服务端没有足够的数据返回，则会等待至超时返回
      group-id: spring-kafka # 指定kafka消费者组
      heartbeat-interval: 10000 # # 协调器心跳间隔时间 heartbeat.interval.ms，需要小于 session.timeout.ms 时间
      #isolation-level: read_uncommitted # isolation.level 事务性消息设置，没有事务不能显示指定
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # key.deserializer key序列化器
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer # value.deserializer value序列化器
      max-poll-records: 500 # 消费者一次拉取请求的最大消息数 max.poll.records
    admin:
      fail-fast: true
    listener:
      missing-topics-fatal: true
      poll-timeout: 60s # 监听超时时间默认5s
      no-poll-threshold: 3 # 超过时间触发的阈值
      log-container-config: true # 初始化是否记录 ListenerConsumer 配置
      idle-event-interval: 60s # 消费空闲发布事件间隔
      ack-count: 10 # COUNT/COUNT_TIME模式 待确认消息阈值
      monitor-interval: 60 # 校验消费者的时间间隔，默认30
    properties:
      max.poll.interval.ms: 30000 # 配置poll最大间隔时间
      heartbeat.interval.ms: 1000 # 协调器心跳
      session.timeout.ms: 30000 # 默认10s kafka消费者与broker的超时时间
      internal.leave.group.on.close: true # 在关闭时离开组，默认true；设置为false
      partition.assignment.strategy: org.apache.kafka.clients.consumer.RangeAssignor # 默认分区策略 消费者组的分区策略不一致可能导致问题
      retry.backoff.ms: 100 # 尝试重试对给定主题分区的失败请求之前等待的时间。这避免了在某些故障场景下在紧密循环中重复发送请求。

